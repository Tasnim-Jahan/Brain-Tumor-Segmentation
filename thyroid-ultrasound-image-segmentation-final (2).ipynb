{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7292974,"sourceType":"datasetVersion","datasetId":4229888}],"dockerImageVersionId":30627,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\nimport numpy as np\nimport cv2\nfrom glob import glob\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.utils import shuffle\nimport tensorflow as tf\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.utils import CustomObjectScope\nfrom sklearn.metrics import f1_score, jaccard_score, precision_score, recall_score, accuracy_score\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import VGG16, VGG19, MobileNetV2, ResNet50\nfrom tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, Concatenate, MaxPool2D, BatchNormalization, Activation, UpSampling2D, Reshape\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, CSVLogger, EarlyStopping, TensorBoard\nimport albumentations as A","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-31T05:40:30.638151Z","iopub.execute_input":"2023-12-31T05:40:30.638526Z","iopub.status.idle":"2023-12-31T05:40:30.647114Z","shell.execute_reply.started":"2023-12-31T05:40:30.638498Z","shell.execute_reply":"2023-12-31T05:40:30.645983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_dir(path):\n    if not os.path.exists(path):\n        os.makedirs(path)\ncreate_dir(\"files\")\n\ncreate_dir(\"results\")","metadata":{"execution":{"iopub.status.busy":"2023-12-31T03:22:17.386775Z","iopub.execute_input":"2023-12-31T03:22:17.387348Z","iopub.status.idle":"2023-12-31T03:22:17.392865Z","shell.execute_reply.started":"2023-12-31T03:22:17.387317Z","shell.execute_reply":"2023-12-31T03:22:17.391873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Constants\nH, W = 256, 256\n\n# Data Augmentation with Albumentations\ndef augment_data(image, mask, augment=True):\n    if augment:\n        transform = A.Compose([\n            A.HorizontalFlip(p=0.5),\n            A.VerticalFlip(p=0.5),\n            A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, p=0.5),\n            A.Rotate(limit=20, p=0.5),\n            A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=20, p=0.5)\n        ])\n        augmented = transform(image=image, mask=mask)\n        image = augmented['image']\n        mask = augmented['mask']\n    return image, mask\n\n# TensorFlow Dataset Function\ndef tf_dataset(X, Y, batch_size, augment=False):\n    def map_func(x, y):\n        def _parse(x, y):\n            x = x.decode()\n            y = y.decode()\n            x = read_image(x)\n            y = read_mask(y)\n            x, y = augment_data(x, y, augment)\n            return x, y\n\n        x, y = tf.numpy_function(_parse, [x, y], [tf.float32, tf.float32])\n        x.set_shape([H, W, 3])\n        y.set_shape([H, W, 1])\n        return x, y\n\n    dataset = tf.data.Dataset.from_tensor_slices((X, Y))\n    dataset = dataset.map(map_func)\n    dataset = dataset.batch(batch_size)\n    dataset = dataset.prefetch(10)\n    return dataset\n","metadata":{"execution":{"iopub.status.busy":"2023-12-31T03:22:17.394260Z","iopub.execute_input":"2023-12-31T03:22:17.394602Z","iopub.status.idle":"2023-12-31T03:22:17.430093Z","shell.execute_reply.started":"2023-12-31T03:22:17.394571Z","shell.execute_reply":"2023-12-31T03:22:17.429154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Image and mask reading functions\ndef read_image(path):\n    x = cv2.imread(path, cv2.IMREAD_COLOR)\n    x = cv2.resize(x, (W, H))\n    x = x / 255.0\n    x = x.astype(np.float32)\n    return x\n\ndef read_mask(path):\n    x = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n    x = cv2.resize(x, (W, H))\n    x = x / 255.0\n    x = np.expand_dims(x, axis=-1)\n    x = x.astype(np.float32)\n    return x\n\n# Dataset loading and splitting function\ndef load_dataset(path, val_split=0.2):  # Changed split to 20% for validation\n    # Load training images and masks\n    train_images = sorted(glob(os.path.join(path, \"trainval-image\", \"*.jpg\")))\n    train_masks = sorted(glob(os.path.join(path, \"trainval-mask\", \"*.jpg\")))\n\n    # Load test images and masks\n    test_images = sorted(glob(os.path.join(path, \"test-image\", \"*.jpg\")))\n    test_masks = sorted(glob(os.path.join(path, \"test-mask\", \"*.jpg\")))\n\n    # Split training data into training and validation sets\n    train_x, valid_x = train_test_split(train_images, test_size=val_split, random_state=42)\n    train_y, valid_y = train_test_split(train_masks, test_size=val_split, random_state=42)\n\n    return (train_x, train_y), (valid_x, valid_y), (test_images, test_masks)\n\n# Load Dataset\ndataset_path = \"/kaggle/input/nlt3kdata\"\n(train_x, train_y), (valid_x, valid_y), (test_x, test_y) = load_dataset(dataset_path)\nprint(f\"Train: ({len(train_x)}, {len(train_y)})\")\nprint(f\"Valid: ({len(valid_x)}, {len(valid_y)})\")\nprint(f\"Test: ({len(test_x)}, {len(test_y)})\")\n\n# Create Datasets\ntrain_dataset = tf_dataset(train_x, train_y, batch_size=16, augment=True)\nvalid_dataset = tf_dataset(valid_x, valid_y, batch_size=16)\ntest_dataset = tf_dataset(test_x, test_y, batch_size=16)","metadata":{"execution":{"iopub.status.busy":"2023-12-31T03:22:17.432163Z","iopub.execute_input":"2023-12-31T03:22:17.432487Z","iopub.status.idle":"2023-12-31T03:22:21.270899Z","shell.execute_reply.started":"2023-12-31T03:22:17.432461Z","shell.execute_reply":"2023-12-31T03:22:21.269643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Number of images in each set\nnum_train = len(train_x)\nnum_valid = len(valid_x)\nnum_test = len(test_x)\n\n# Set names\nsets = ['Train', 'Validation', 'Test']\n\n# Number of images in each set\ncounts = [num_train, num_valid, num_test]\n\n# Create a bar chart\nplt.figure(figsize=(10, 6))\nplt.bar(sets, counts, color=['blue', 'green', 'red'])\nplt.title('Number of Images in Each Dataset Split')\nplt.xlabel('Dataset Split')\nplt.ylabel('Number of Images')\nplt.ylim(0, max(counts) + 10)  # Set y-axis limit slightly higher than the max count\n\n# Add text labels for each bar\nfor i in range(len(sets)):\n    plt.text(i, counts[i] + 1, str(counts[i]), ha = 'center', color='black')\n\n# Show the plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-31T03:22:21.272209Z","iopub.execute_input":"2023-12-31T03:22:21.272589Z","iopub.status.idle":"2023-12-31T03:22:21.556460Z","shell.execute_reply.started":"2023-12-31T03:22:21.272552Z","shell.execute_reply":"2023-12-31T03:22:21.555475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Number of images in each set\nnum_train = len(train_x)\nnum_valid = len(valid_x)\nnum_test = len(test_x)\n\n# Set names\nsets = ['Train', 'Validation', 'Test']\n\n# Number of images in each set\ncounts = [num_train, num_valid, num_test]\n\n# Create a pie chart\nplt.figure(figsize=(8, 8))\nplt.pie(counts, labels=sets, autopct='%1.1f%%', startangle=140, colors=['skyblue', 'lightgreen', 'lightcoral'])\nplt.title('Distribution of Images in Dataset Splits')\n\n# Show the plot\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-12-31T03:22:21.557795Z","iopub.execute_input":"2023-12-31T03:22:21.558418Z","iopub.status.idle":"2023-12-31T03:22:21.767433Z","shell.execute_reply.started":"2023-12-31T03:22:21.558383Z","shell.execute_reply":"2023-12-31T03:22:21.766139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model parameters\nlr = 1e-4  # Lower learning rate\nnum_epochs = 500  # Increase number of epochs\n\nbatch_size = 16\n#lr = 1e-4\n#num_epochs = 300\nmodel_path = os.path.join(\"files\", \"model.h5\")\ncsv_path = os.path.join(\"files\", \"log.csv\")\ndataset_path=\"/kaggle/input/tn3k-thyroid-nodule-region-segmentation-dataset\"\n\ncallbacks = [\n    ModelCheckpoint(model_path, verbose=1, save_best_only=True),\n    ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-7, verbose=1),\n    CSVLogger(csv_path),\n    EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=False),\n]\n\nfrom tensorflow.keras.backend import sum as K_sum\n\ndef dice_coef(y_true, y_pred, smooth=1e-6):\n    y_true_flat = K.flatten(y_true)\n    y_pred_flat = K.flatten(y_pred)\n    intersection = K_sum(y_true_flat * y_pred_flat)\n    return (2. * intersection + smooth) / (K_sum(y_true_flat) + K_sum(y_pred_flat) + smooth)\n\ndef dice_loss(y_true, y_pred):\n    return 1.0 - dice_coef(y_true, y_pred)\n\n\ndef iou(y_true, y_pred):\n    def f(y_true, y_pred):\n        intersection = K.sum(K.flatten(y_true) * K.flatten(y_pred))\n        union = K.sum(K.flatten(y_true)) + K.sum(K.flatten(y_pred)) - intersection\n        return (intersection + K.epsilon()) / (union + K.epsilon())\n    return tf.numpy_function(f, [y_true, y_pred], tf.float32)","metadata":{"execution":{"iopub.status.busy":"2023-12-31T03:22:21.769386Z","iopub.execute_input":"2023-12-31T03:22:21.770758Z","iopub.status.idle":"2023-12-31T03:22:21.791289Z","shell.execute_reply.started":"2023-12-31T03:22:21.770698Z","shell.execute_reply":"2023-12-31T03:22:21.789781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Conv Block\ndef conv_block(inputs, num_filters):\n    x = Conv2D(num_filters, 3, padding=\"same\")(inputs)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n    return x\n\n# Encoder Block\ndef encoder_block(inputs, num_filters):\n    x = conv_block(inputs, num_filters)\n    p = MaxPool2D((2, 2))(x)\n    return x, p\n\n# Decoder Block\ndef decoder_block(inputs, skip_features, num_filters):\n    x = Conv2DTranspose(num_filters, 2, strides=2, padding=\"same\")(inputs)\n    x = Concatenate()([x, skip_features])\n    x = conv_block(x, num_filters)\n    return x\n","metadata":{"execution":{"iopub.status.busy":"2023-12-31T03:22:21.793504Z","iopub.execute_input":"2023-12-31T03:22:21.794029Z","iopub.status.idle":"2023-12-31T03:22:21.807254Z","shell.execute_reply.started":"2023-12-31T03:22:21.793980Z","shell.execute_reply":"2023-12-31T03:22:21.806198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Build U-Net\ndef unet(input_shape):\n    inputs = Input(input_shape)\n\n    s1, p1 = encoder_block(inputs, 64)\n    s2, p2 = encoder_block(p1, 128)\n    s3, p3 = encoder_block(p2, 256)\n    s4, p4 = encoder_block(p3, 512)\n\n    b1 = conv_block(p4, 1024)\n\n    d1 = decoder_block(b1, s4, 512)\n    d2 = decoder_block(d1, s3, 256)\n    d3 = decoder_block(d2, s2, 128)\n    d4 = decoder_block(d3, s1, 64)\n\n    outputs = Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(d4)\n\n    model = Model(inputs, outputs, name=\"UNET\")\n    return model\n\n# Initialize the model\nunet_model = unet((H, W, 3))\n\n# Compile the model with the IoU metric, dice coefficient loss, and optimizer\nunet_model.compile(loss=dice_loss, optimizer=Adam(lr), metrics=[dice_coef, 'accuracy', iou])\n\n# Print the model summary to check the final model architecture\nunet_model.summary()\n\n# Train the model using the same datasets and callbacks you've defined\nhistory_unet = unet_model.fit(\n    train_dataset,\n    epochs=num_epochs,\n    validation_data=valid_dataset,\n    callbacks=callbacks\n)\n\n# Save training history\nnp.save('history_unet.npy', history_unet.history)\n\n# Evaluate the model on the test set and display test metrics\ntest_metrics = unet_model.evaluate(test_dataset)\nprint(f\"Unet Test Loss: {test_metrics[0]}\")\nprint(f\"Unet Test Dice Coefficient: {test_metrics[1]}\")\nprint(f\"Unet Test Accuracy: {test_metrics[2]}\")\nprint(f\"Unet Test IoU: {test_metrics[3]}\")\n\n# Save the test metrics to a file\nwith open('unet_test_metrics.txt', 'w') as file:\n    file.write(str(test_metrics))\n","metadata":{"execution":{"iopub.status.busy":"2023-12-31T03:22:21.808590Z","iopub.execute_input":"2023-12-31T03:22:21.808879Z","iopub.status.idle":"2023-12-31T04:51:10.938531Z","shell.execute_reply.started":"2023-12-31T03:22:21.808854Z","shell.execute_reply":"2023-12-31T04:51:10.937474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nmetrics = pd.read_csv(\"/kaggle/working/files/log.csv\")\nmetrics.tail(2)","metadata":{"execution":{"iopub.status.busy":"2023-12-31T04:51:10.941468Z","iopub.execute_input":"2023-12-31T04:51:10.941778Z","iopub.status.idle":"2023-12-31T04:51:10.972789Z","shell.execute_reply.started":"2023-12-31T04:51:10.941750Z","shell.execute_reply":"2023-12-31T04:51:10.971723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metrics[['dice_coef','val_dice_coef']].plot()","metadata":{"execution":{"iopub.status.busy":"2023-12-31T04:51:10.974102Z","iopub.execute_input":"2023-12-31T04:51:10.974508Z","iopub.status.idle":"2023-12-31T04:51:11.231403Z","shell.execute_reply.started":"2023-12-31T04:51:10.974469Z","shell.execute_reply":"2023-12-31T04:51:11.230449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metrics[['accuracy','val_accuracy']].plot()","metadata":{"execution":{"iopub.status.busy":"2023-12-31T04:51:11.232503Z","iopub.execute_input":"2023-12-31T04:51:11.232758Z","iopub.status.idle":"2023-12-31T04:51:11.538528Z","shell.execute_reply.started":"2023-12-31T04:51:11.232735Z","shell.execute_reply":"2023-12-31T04:51:11.537495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metrics[['loss','val_loss']].plot()","metadata":{"execution":{"iopub.status.busy":"2023-12-31T04:51:11.539846Z","iopub.execute_input":"2023-12-31T04:51:11.540243Z","iopub.status.idle":"2023-12-31T04:51:11.833154Z","shell.execute_reply.started":"2023-12-31T04:51:11.540206Z","shell.execute_reply":"2023-12-31T04:51:11.832258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\ndef save_results(image, mask, y_pred, save_image_path):\n    mask = np.expand_dims(mask, axis=-1)\n    mask = np.concatenate([mask, mask, mask], axis=-1)\n\n    y_pred = np.expand_dims(y_pred, axis=-1)\n    y_pred = np.concatenate([y_pred, y_pred, y_pred], axis=-1)\n    y_pred = y_pred * 255\n\n    line = np.ones((H, 10, 3)) * 255\n\n    cat_images = np.concatenate([image, line, mask, line, y_pred], axis=1)\n    cv2.imwrite(save_image_path, cat_images)\n    \n    \"\"\"Prediction and Evaluation\"\"\"\nSCORE = []\nfor x, y in tqdm(zip(test_x, test_y), total=len(test_y)):\n    \"\"\" Extracting the name \"\"\"\n    name = x.split(\"/\")[-1]\n\n    \"\"\" Reading the image \"\"\"\n    image = cv2.imread(x, cv2.IMREAD_COLOR) ## [H, w, 3]\n    image = cv2.resize(image, (W, H))       ## [H, w, 3]\n    x = image/255.0                         ## [H, w, 3]\n    x = np.expand_dims(x, axis=0)           ## [1, H, w, 3]\n\n    \"\"\" Reading the mask \"\"\"\n    mask = cv2.imread(y, cv2.IMREAD_GRAYSCALE)\n    mask = cv2.resize(mask, (W, H))\n\n    \"\"\" Prediction \"\"\"\n    y_pred = unet_model.predict(x, verbose=0)[0]\n    y_pred = np.squeeze(y_pred, axis=-1)\n    y_pred = y_pred >= 0.5\n    y_pred = y_pred.astype(np.int32)\n\n    \"\"\" Saving the prediction \"\"\"\n    save_image_path = os.path.join(\"results\", name)\n    save_results(image, mask, y_pred, save_image_path)\n\n    \"\"\" Flatten the array \"\"\"\n    mask = mask/255.0\n    mask = (mask > 0.5).astype(np.int32).flatten()\n    y_pred = y_pred.flatten()\n\n    \"\"\" Calculating the metrics values \"\"\"\n    accuracy = accuracy_score(mask, y_pred)\n    #print(accuracy)\n    f1_value = f1_score(mask, y_pred, labels=[0, 1], average=\"binary\")\n    jac_value = jaccard_score(mask, y_pred, labels=[0, 1], average=\"binary\")\n    recall_value = recall_score(mask, y_pred, labels=[0, 1], average=\"binary\", zero_division=0)\n    precision_value = precision_score(mask, y_pred, labels=[0, 1], average=\"binary\", zero_division=0)\n    SCORE.append([name, accuracy, f1_value, jac_value, recall_value, precision_value])\n\n\"\"\" Metrics values \"\"\"\nscore = [s[1:]for s in SCORE]\nscore = np.mean(score, axis=0)\nprint(f\"Accuracy: {score[0]:0.5f}\")\nprint(f\"F1: {score[1]:0.5f}\")\nprint(f\"Jaccard: {score[2]:0.5f}\")\nprint(f\"Recall: {score[3]:0.5f}\")\nprint(f\"Precision: {score[4]:0.5f}\")\n\ndf = pd.DataFrame(SCORE, columns=[\"Image\",\"Accuracy\", \"F1\", \"Jaccard\", \"Recall\", \"Precision\"])\ndf.to_csv(\"files/score.csv\", index=None)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-31T05:47:26.491549Z","iopub.execute_input":"2023-12-31T05:47:26.491971Z","iopub.status.idle":"2023-12-31T05:49:30.394388Z","shell.execute_reply.started":"2023-12-31T05:47:26.491922Z","shell.execute_reply":"2023-12-31T05:49:30.393440Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores = pd.read_csv(\"/kaggle/working/files/score.csv\")\nscores.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-31T05:50:05.624236Z","iopub.execute_input":"2023-12-31T05:50:05.624621Z","iopub.status.idle":"2023-12-31T05:50:05.640964Z","shell.execute_reply.started":"2023-12-31T05:50:05.624589Z","shell.execute_reply":"2023-12-31T05:50:05.640076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_dir(path):\n    if not os.path.exists(path):\n        os.makedirs(path)\n\ncreate_dir(\"files_vgg16\")\ncreate_dir(\"results_vgg16\")\n\nmodel_path_vgg16 = os.path.join(\"files_vgg16\", \"model_vgg16.h5\")\ncsv_path_vgg16 = os.path.join(\"files_vgg16\", \"log_vgg16.csv\")\n\ncallbacks_vgg16 = [\n    ModelCheckpoint(model_path_vgg16, verbose=1, save_best_only=True),\n    ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-7, verbose=1),\n    CSVLogger(csv_path_vgg16),\n    EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=False),\n]","metadata":{"execution":{"iopub.status.busy":"2023-12-31T05:50:25.660604Z","iopub.execute_input":"2023-12-31T05:50:25.660992Z","iopub.status.idle":"2023-12-31T05:50:25.668331Z","shell.execute_reply.started":"2023-12-31T05:50:25.660960Z","shell.execute_reply":"2023-12-31T05:50:25.667193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the U-Net model with VGG16 encoder\ndef build_vgg16(input_shape):\n    # Encoder: load VGG16 with pre-trained ImageNet weights\n    encoder = VGG16(include_top=False, weights='imagenet', input_tensor=Input(shape=input_shape))\n\n    # Set the encoder layers to not be trainable\n    for layer in encoder.layers:\n        layer.trainable = False\n\n    # Skip connections from specific layers in VGG16\n    skip_connections = ['block1_conv2', 'block2_conv2', 'block3_conv3', 'block4_conv3']\n    encoder_outputs = [encoder.get_layer(name).output for name in skip_connections]\n\n    # Decoder\n    x = encoder.output\n    for i in range(len(encoder_outputs)):\n        num_filters = 512 // (2 ** i)\n        x = Conv2DTranspose(num_filters, (2, 2), strides=(2, 2), padding='same')(x)\n        skip_output = encoder_outputs[-(i + 1)]\n        skip_output = tf.image.resize(skip_output, tf.shape(x)[1:3], method='nearest')\n        x = Concatenate()([x, skip_output])\n        x = conv_block(x, num_filters)\n\n    # Final Conv2DTranspose layer to upscale to the original image size\n    x = Conv2DTranspose(num_filters, (2, 2), strides=(2, 2), padding='same')(x)\n    outputs = Conv2D(1, (1, 1), activation='sigmoid', padding='same')(x)\n\n    # Create the model\n    model = Model(inputs=encoder.input, outputs=outputs)\n    return model\n\n# Initialize the model\nvgg16_model = build_vgg16((H, W, 3))\n\n# Compile the model with the IoU metric, dice coefficient loss, and optimizer\nvgg16_model.compile(loss=dice_loss, optimizer=Adam(lr), metrics=[dice_coef, 'accuracy', iou])\n\n# Print the model summary to check the final model architecture\nvgg16_model.summary()\n\n\n# Train the VGG16 U-Net model using the defined callbacks for VGG16\nhistory_vgg16 = vgg16_model.fit(\n    train_dataset,\n    epochs=num_epochs,\n    validation_data=valid_dataset,\n    callbacks=callbacks_vgg16  # Using callbacks_vgg16 here\n)\n\n# Save training history\nnp.save('history_vgg16.npy', history_vgg16.history)\n\n\n# Evaluate the model on the test set and display test metrics\nvgg16_test_metrics = vgg16_model.evaluate(test_dataset)\nprint(f\"VGG16 Test Loss: {vgg16_test_metrics[0]}\")\nprint(f\"VGG16 Test Dice Coefficient: {vgg16_test_metrics[1]}\")\nprint(f\"VGG16 Test Accuracy: {vgg16_test_metrics[2]}\")\nprint(f\"VGG16 Test IoU: {vgg16_test_metrics[3]}\")\n\n# Save training history\nnp.save('history_vgg16.npy', history_vgg16.history)\n\n# Save the test metrics to a file\nwith open('vgg16_test_metrics.txt', 'w') as file:\n    file.write(str(vgg16_test_metrics))","metadata":{"execution":{"iopub.status.busy":"2023-12-31T05:51:12.388145Z","iopub.execute_input":"2023-12-31T05:51:12.388619Z","iopub.status.idle":"2023-12-31T06:20:27.898270Z","shell.execute_reply.started":"2023-12-31T05:51:12.388584Z","shell.execute_reply":"2023-12-31T06:20:27.897311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate the model on the test set and display test metrics\nvgg16_test_metrics = vgg16_model.evaluate(test_dataset)\nprint(f\"VGG16 Test Loss: {vgg16_test_metrics[0]}\")\nprint(f\"VGG16 Test Dice Coefficient: {vgg16_test_metrics[1]}\")\nprint(f\"VGG16 Test Accuracy: {vgg16_test_metrics[2]}\")\nprint(f\"VGG16 Test IoU: {vgg16_test_metrics[3]}\")\n\n# Save training history\nnp.save('history_vgg16.npy', history_vgg16.history)\n\n# Save the test metrics to a file\nwith open('vgg16_test_metrics.txt', 'w') as file:\n    file.write(str(vgg16_test_metrics))","metadata":{"execution":{"iopub.status.busy":"2023-12-31T06:23:53.889886Z","iopub.execute_input":"2023-12-31T06:23:53.890779Z","iopub.status.idle":"2023-12-31T06:23:58.844327Z","shell.execute_reply.started":"2023-12-31T06:23:53.890746Z","shell.execute_reply":"2023-12-31T06:23:58.843332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"   \"\"\"Prediction and Evaluation\"\"\"\nSCORE_vgg16 = []\nfor x, y in tqdm(zip(test_x, test_y), total=len(test_y)):\n    \"\"\" Extracting the name \"\"\"\n    name = x.split(\"/\")[-1]\n\n    \"\"\" Reading the image \"\"\"\n    image = cv2.imread(x, cv2.IMREAD_COLOR) ## [H, w, 3]\n    image = cv2.resize(image, (W, H))       ## [H, w, 3]\n    x = image/255.0                         ## [H, w, 3]\n    x = np.expand_dims(x, axis=0)           ## [1, H, w, 3]\n\n    \"\"\" Reading the mask \"\"\"\n    mask = cv2.imread(y, cv2.IMREAD_GRAYSCALE)\n    mask = cv2.resize(mask, (W, H))\n\n    \"\"\" Prediction \"\"\"\n    y_pred = vgg16_model.predict(x, verbose=0)[0]\n    y_pred = np.squeeze(y_pred, axis=-1)\n    y_pred = y_pred >= 0.5\n    y_pred = y_pred.astype(np.int32)\n\n    \"\"\" Saving the prediction \"\"\"\n    save_image_path = os.path.join(\"results_vgg16\", name)\n    save_results(image, mask, y_pred, save_image_path)\n\n    \"\"\" Flatten the array \"\"\"\n    mask = mask/255.0\n    mask = (mask > 0.5).astype(np.int32).flatten()\n    y_pred = y_pred.flatten()\n\n    \"\"\" Calculating the metrics values \"\"\"\n    accuracy = accuracy_score(mask, y_pred)\n    f1_value = f1_score(mask, y_pred, labels=[0, 1], average=\"binary\")\n    jac_value = jaccard_score(mask, y_pred, labels=[0, 1], average=\"binary\")\n    recall_value = recall_score(mask, y_pred, labels=[0, 1], average=\"binary\", zero_division=0)\n    precision_value = precision_score(mask, y_pred, labels=[0, 1], average=\"binary\", zero_division=0)\n    SCORE_vgg16.append([name, accuracy, f1_value, jac_value, recall_value, precision_value])\n\n\"\"\" Metrics values \"\"\"\nscore_vgg16 = [s[1:]for s in SCORE_vgg16]\nscore_vgg16 = np.mean(score_vgg16, axis=0)\nprint(f\"Accuracy: {score_vgg16[0]:0.5f}\")\nprint(f\"F1: {score_vgg16[1]:0.5f}\")\nprint(f\"Jaccard: {score_vgg16[2]:0.5f}\")\nprint(f\"Recall: {score_vgg16[3]:0.5f}\")\nprint(f\"Precision: {score_vgg16[4]:0.5f}\")\n\ndf = pd.DataFrame(SCORE_vgg16, columns=[\"Image\", \"Accuracy\",\"F1\", \"Jaccard\", \"Recall\", \"Precision\"])\ndf.to_csv(\"files/score_vgg16.csv\", index=None)","metadata":{"execution":{"iopub.status.busy":"2023-12-31T06:24:05.553026Z","iopub.execute_input":"2023-12-31T06:24:05.553682Z","iopub.status.idle":"2023-12-31T06:26:11.879553Z","shell.execute_reply.started":"2023-12-31T06:24:05.553646Z","shell.execute_reply":"2023-12-31T06:26:11.878421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores = pd.read_csv(\"/kaggle/working/files/score_vgg16.csv\")\nscores.head(3)","metadata":{"execution":{"iopub.status.busy":"2023-12-31T06:26:56.170302Z","iopub.execute_input":"2023-12-31T06:26:56.171114Z","iopub.status.idle":"2023-12-31T06:26:56.186981Z","shell.execute_reply.started":"2023-12-31T06:26:56.171079Z","shell.execute_reply":"2023-12-31T06:26:56.186098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_dir(path):\n    if not os.path.exists(path):\n        os.makedirs(path)\n\ncreate_dir(\"files_vgg19\")\ncreate_dir(\"results_vgg19\")\n\nmodel_path_vgg19 = os.path.join(\"files_vgg19\", \"model_vgg19.h5\")\ncsv_path_vgg19 = os.path.join(\"files_vgg19\", \"log_vgg19.csv\")\n\ncallbacks_vgg19 = [\n    ModelCheckpoint(model_path_vgg19, verbose=1, save_best_only=True),\n    ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-7, verbose=1),\n    CSVLogger(csv_path_vgg19),\n    EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=False),\n]","metadata":{"execution":{"iopub.status.busy":"2023-12-31T06:27:12.534784Z","iopub.execute_input":"2023-12-31T06:27:12.535559Z","iopub.status.idle":"2023-12-31T06:27:12.542689Z","shell.execute_reply.started":"2023-12-31T06:27:12.535527Z","shell.execute_reply":"2023-12-31T06:27:12.541674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.applications import VGG19\nfrom tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, Concatenate, BatchNormalization, Activation\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nimport numpy as np\nimport os\n\n# Define the U-Net model with VGG19 encoder\ndef build_vgg19(input_shape):\n    # Encoder: load VGG19 with pre-trained ImageNet weights\n    encoder = VGG19(include_top=False, weights='imagenet', input_tensor=Input(shape=input_shape))\n\n    # Set the encoder layers to not be trainable\n    for layer in encoder.layers:\n        layer.trainable = False\n\n    # Skip connections from specific layers in VGG19\n    skip_connections = ['block1_conv2', 'block2_conv2', 'block3_conv4', 'block4_conv4']\n    encoder_outputs = [encoder.get_layer(name).output for name in skip_connections]\n\n    # Decoder\n    x = encoder.output\n    for i in range(len(encoder_outputs)):\n        num_filters = 512 // (2 ** i)\n        x = Conv2DTranspose(num_filters, (2, 2), strides=(2, 2), padding='same')(x)\n        skip_output = encoder_outputs[-(i + 1)]\n        skip_output = tf.image.resize(skip_output, tf.shape(x)[1:3], method='nearest')\n        x = Concatenate()([x, skip_output])\n        x = conv_block(x, num_filters)\n\n    # Final Conv2DTranspose layer to upscale to the original image size\n    x = Conv2DTranspose(num_filters, (2, 2), strides=(2, 2), padding='same')(x)\n    outputs = Conv2D(1, (1, 1), activation='sigmoid', padding='same')(x)\n\n    # Create the model\n    model = Model(inputs=encoder.input, outputs=outputs)\n    return model\n\n# Initialize the model\nvgg19_model = build_vgg19((H, W, 3))\n\n# Compile the model with the IoU metric, dice coefficient loss, and optimizer\nvgg19_model.compile(loss=dice_loss, optimizer=Adam(lr), metrics=[dice_coef, 'accuracy', iou])\n\n# Print the model summary to check the final model architecture\nvgg19_model.summary()\n\n# Train the VGG19 U-Net model\nhistory_vgg19 = vgg19_model.fit(\n    train_dataset,\n    epochs=num_epochs,\n    validation_data=valid_dataset,\n    callbacks=callbacks_vgg19  # Make sure to define callbacks_vgg19\n)\n\n# Save training history\nnp.save('history_vgg19.npy', history_vgg19.history)\n\n# Evaluate the model on the test set and display test metrics\nvgg19_test_metrics = vgg19_model.evaluate(test_dataset)\nprint(f\"VGG19 Test Loss: {vgg19_test_metrics[0]}\")\nprint(f\"VGG19 Test Dice Coefficient: {vgg19_test_metrics[1]}\")\nprint(f\"VGG19 Test Accuracy: {vgg19_test_metrics[2]}\")\nprint(f\"VGG19 Test IoU: {vgg19_test_metrics[3]}\")\n\n# Save the test metrics to a file\nwith open('vgg19_test_metrics.txt', 'w') as file:\n    file.write(str(vgg19_test_metrics))","metadata":{"execution":{"iopub.status.busy":"2023-12-31T06:27:15.768383Z","iopub.execute_input":"2023-12-31T06:27:15.768772Z","iopub.status.idle":"2023-12-31T07:11:28.577318Z","shell.execute_reply.started":"2023-12-31T06:27:15.768734Z","shell.execute_reply":"2023-12-31T07:11:28.576228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"  \"\"\"Prediction and Evaluation\"\"\"\nSCORE_vgg19= []\nfor x, y in tqdm(zip(test_x, test_y), total=len(test_y)):\n    \"\"\" Extracting the name \"\"\"\n    name = x.split(\"/\")[-1]\n\n    \"\"\" Reading the image \"\"\"\n    image = cv2.imread(x, cv2.IMREAD_COLOR) ## [H, w, 3]\n    image = cv2.resize(image, (W, H))       ## [H, w, 3]\n    x = image/255.0                         ## [H, w, 3]\n    x = np.expand_dims(x, axis=0)           ## [1, H, w, 3]\n\n    \"\"\" Reading the mask \"\"\"\n    mask = cv2.imread(y, cv2.IMREAD_GRAYSCALE)\n    mask = cv2.resize(mask, (W, H))\n\n    \"\"\" Prediction \"\"\"\n    y_pred = vgg19_model.predict(x, verbose=0)[0]\n    y_pred = np.squeeze(y_pred, axis=-1)\n    y_pred = y_pred >= 0.5\n    y_pred = y_pred.astype(np.int32)\n\n    \"\"\" Saving the prediction \"\"\"\n    save_image_path = os.path.join(\"results_vgg19\", name)\n    save_results(image, mask, y_pred, save_image_path)\n\n    \"\"\" Flatten the array \"\"\"\n    mask = mask/255.0\n    mask = (mask > 0.5).astype(np.int32).flatten()\n    y_pred = y_pred.flatten()\n\n    \"\"\" Calculating the metrics values \"\"\"\n    accuracy = accuracy_score(mask, y_pred)\n    f1_value = f1_score(mask, y_pred, labels=[0, 1], average=\"binary\")\n    jac_value = jaccard_score(mask, y_pred, labels=[0, 1], average=\"binary\")\n    recall_value = recall_score(mask, y_pred, labels=[0, 1], average=\"binary\", zero_division=0)\n    precision_value = precision_score(mask, y_pred, labels=[0, 1], average=\"binary\", zero_division=0)\n    SCORE_vgg19.append([name, accuracy, f1_value, jac_value, recall_value, precision_value])\n\n\"\"\" Metrics values \"\"\"\nscore_vgg19 = [s[1:]for s in SCORE_vgg19]\nscore_vgg19 = np.mean(score_vgg19, axis=0)\nprint(f\"Accuracy: {score_vgg19[0]:0.5f}\")\nprint(f\"F1: {score_vgg19[1]:0.5f}\")\nprint(f\"Jaccard: {score_vgg19[2]:0.5f}\")\nprint(f\"Recall: {score_vgg19[3]:0.5f}\")\nprint(f\"Precision: {score_vgg19[4]:0.5f}\")\n\ndf = pd.DataFrame(SCORE_vgg19, columns=[\"Image\", \"Accuracy\", \"F1\", \"Jaccard\", \"Recall\", \"Precision\"])\ndf.to_csv(\"files/score_vgg19.csv\", index=None)","metadata":{"execution":{"iopub.status.busy":"2023-12-31T07:12:12.322891Z","iopub.execute_input":"2023-12-31T07:12:12.323878Z","iopub.status.idle":"2023-12-31T07:14:04.217036Z","shell.execute_reply.started":"2023-12-31T07:12:12.323845Z","shell.execute_reply":"2023-12-31T07:14:04.216126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores = pd.read_csv(\"/kaggle/working/files/score_vgg19.csv\")\nscores.head(3)","metadata":{"execution":{"iopub.status.busy":"2023-12-31T07:14:12.272164Z","iopub.execute_input":"2023-12-31T07:14:12.272535Z","iopub.status.idle":"2023-12-31T07:14:12.289441Z","shell.execute_reply.started":"2023-12-31T07:14:12.272503Z","shell.execute_reply":"2023-12-31T07:14:12.288253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_dir(path):\n    if not os.path.exists(path):\n        os.makedirs(path)\n\ncreate_dir(\"files_resnet50\")\ncreate_dir(\"results_resnet50\")\n\nmodel_path_resnet50 = os.path.join(\"files_resnet50\", \"model_resnet50.h5\")\ncsv_path_resnet50 = os.path.join(\"files_resnet50\", \"log_resnet50.csv\")\n\ncallbacks_resnet50 = [\n    ModelCheckpoint(model_path_resnet50, verbose=1, save_best_only=True),\n    ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-7, verbose=1),\n    CSVLogger(csv_path_resnet50),\n    EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=False),\n]","metadata":{"execution":{"iopub.status.busy":"2023-12-31T07:14:17.325524Z","iopub.execute_input":"2023-12-31T07:14:17.325927Z","iopub.status.idle":"2023-12-31T07:14:17.334097Z","shell.execute_reply.started":"2023-12-31T07:14:17.325896Z","shell.execute_reply":"2023-12-31T07:14:17.332900Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.layers import Input, Conv2DTranspose, Concatenate, Conv2D\nfrom tensorflow.keras.models import Model\nimport tensorflow as tf\nfrom tensorflow.keras.optimizers import Adam\nimport numpy as np\n\n# Define the U-Net model with ResNet50 encoder\ndef build_resnet50(input_shape):\n    # Encoder: load ResNet50 with pre-trained ImageNet weights\n    encoder = ResNet50(include_top=False, weights='imagenet', input_tensor=Input(shape=input_shape))\n\n    # Set the encoder layers to not be trainable\n    for layer in encoder.layers:\n        layer.trainable = False\n\n    # Skip connections from specific layers in ResNet50\n    skip_connections = ['conv2_block3_out', 'conv3_block4_out', 'conv4_block6_out', 'conv5_block3_out']\n    encoder_outputs = [encoder.get_layer(name).output for name in skip_connections]\n\n    # Decoder\n    x = encoder.output\n    for i in range(len(encoder_outputs)):\n        num_filters = 256 // (2 ** i)\n        x = Conv2DTranspose(num_filters, (2, 2), strides=(2, 2), padding='same')(x)\n        skip_output = encoder_outputs[-(i + 1)]\n        skip_output = tf.image.resize(skip_output, tf.shape(x)[1:3], method='nearest')\n        x = Concatenate()([x, skip_output])\n        x = conv_block(x, num_filters)\n\n    # Final Conv2DTranspose layer to upscale to the original image size\n    x = Conv2DTranspose(num_filters, (2, 2), strides=(2, 2), padding='same')(x)\n    outputs = Conv2D(1, (1, 1), activation='sigmoid', padding='same')(x)\n\n    # Create the model\n    model = Model(inputs=encoder.input, outputs=outputs)\n    return model\n\n# Initialize the model\nresnet50_model = build_resnet50((H, W, 3))\n\n# Compile the model\nresnet50_model.compile(loss=dice_loss, optimizer=Adam(lr), metrics=[dice_coef, 'accuracy', iou])\n\n# Print the model summary to check the final model architecture\nresnet50_model.summary()\n\n# Train the model using the same datasets and callbacks you've defined\nhistory_resnet50 = resnet50_model.fit(\n    train_dataset,\n    epochs=num_epochs,\n    validation_data=valid_dataset,\n    callbacks=callbacks_resnet50\n)\n\n# Save training history\nnp.save('history_resnet50.npy', history_resnet50.history)\n\n# Evaluate the model on your test dataset\nresnet50_test_metrics = resnet50_model.evaluate(test_dataset)\nprint(f\"ResNet50 Test Loss: {resnet50_test_metrics[0]}\")\nprint(f\"ResNet50 Test Dice Coefficient: {resnet50_test_metrics[1]}\")\nprint(f\"ResNet50 Test Accuracy: {resnet50_test_metrics[2]}\")\nprint(f\"ResNet50 Test IoU: {resnet50_test_metrics[3]}\")\n\n# Save and display the test metrics\nwith open('resnet50_test_metrics.txt', 'w') as file:\n    file.write(str(resnet50_test_metrics))","metadata":{"execution":{"iopub.status.busy":"2023-12-31T07:15:22.317465Z","iopub.execute_input":"2023-12-31T07:15:22.318239Z","iopub.status.idle":"2023-12-31T07:42:54.979797Z","shell.execute_reply.started":"2023-12-31T07:15:22.318203Z","shell.execute_reply":"2023-12-31T07:42:54.978809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"   \"\"\"Prediction and Evaluation\"\"\"\nSCORE_resnet50= []\nfor x, y in tqdm(zip(test_x, test_y), total=len(test_y)):\n    \"\"\" Extracting the name \"\"\"\n    name = x.split(\"/\")[-1]\n    \n    \"\"\" Reading the image \"\"\"\n    image = cv2.imread(x, cv2.IMREAD_COLOR) ## [H, w, 3]\n    image = cv2.resize(image, (W, H))       ## [H, w, 3]\n    x = image/255.0                         ## [H, w, 3]\n    x = np.expand_dims(x, axis=0)           ## [1, H, w, 3]\n\n    \"\"\" Reading the mask \"\"\"\n    mask = cv2.imread(y, cv2.IMREAD_GRAYSCALE)\n    mask = cv2.resize(mask, (W, H))\n\n    \"\"\" Prediction \"\"\"\n    y_pred = resnet50_model.predict(x, verbose=0)[0]\n    y_pred = np.squeeze(y_pred, axis=-1)\n    y_pred = y_pred >= 0.5\n    y_pred = y_pred.astype(np.int32)\n\n    \"\"\" Saving the prediction \"\"\"\n    save_image_path = os.path.join(\"results_resnet50 \", name)\n    save_results(image, mask, y_pred, save_image_path)\n\n    \"\"\" Flatten the array \"\"\"\n    mask = mask/255.0\n    mask = (mask > 0.5).astype(np.int32).flatten()\n    y_pred = y_pred.flatten()\n\n    \"\"\" Calculating the metrics values \"\"\"\n    accuracy = accuracy_score(mask, y_pred)\n    f1_value = f1_score(mask, y_pred, labels=[0, 1], average=\"binary\")\n    jac_value = jaccard_score(mask, y_pred, labels=[0, 1], average=\"binary\")\n    recall_value = recall_score(mask, y_pred, labels=[0, 1], average=\"binary\", zero_division=0)\n    precision_value = precision_score(mask, y_pred, labels=[0, 1], average=\"binary\", zero_division=0)\n    SCORE_resnet50.append([name, accuracy, f1_value, jac_value, recall_value, precision_value])\n\n\"\"\" Metrics values \"\"\"\nscore_resnet50 = [s[1:]for s in SCORE_resnet50]\nscore_resnet50 = np.mean(score_resnet50, axis=0)\nprint(f\"Accuracy: {score_resnet50[0]:0.5f}\")\nprint(f\"F1: {score_resnet50[1]:0.5f}\")\nprint(f\"Jaccard: {score_resnet50[2]:0.5f}\")\nprint(f\"Recall: {score_resnet50[3]:0.5f}\")\nprint(f\"Precision: {score_resnet50[4]:0.5f}\")\n\ndf = pd.DataFrame(SCORE_resnet50, columns=[\"Image\", \"Accuracy\", \"F1\", \"Jaccard\", \"Recall\", \"Precision\"])\ndf.to_csv(\"files/score_resnet50.csv\", index=None)","metadata":{"execution":{"iopub.status.busy":"2023-12-31T08:03:43.732234Z","iopub.execute_input":"2023-12-31T08:03:43.732634Z","iopub.status.idle":"2023-12-31T08:05:50.476667Z","shell.execute_reply.started":"2023-12-31T08:03:43.732605Z","shell.execute_reply":"2023-12-31T08:05:50.475447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores = pd.read_csv(\"/kaggle/working/files/score_resnet50.csv\")\nscores.head(3)","metadata":{"execution":{"iopub.status.busy":"2023-12-31T08:17:56.125153Z","iopub.execute_input":"2023-12-31T08:17:56.126189Z","iopub.status.idle":"2023-12-31T08:17:56.144817Z","shell.execute_reply.started":"2023-12-31T08:17:56.126147Z","shell.execute_reply":"2023-12-31T08:17:56.143456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_dir(path):\n    if not os.path.exists(path):\n        os.makedirs(path)\n\ncreate_dir(\"files_mobilenetv2\")\ncreate_dir(\"results_mobilenetv2\")\n\nmodel_path_mobilenetv2 = os.path.join(\"files_mobilenetv2\", \"model_mobilenetv2.h5\")\ncsv_path_mobilenetv2 = os.path.join(\"files_mobilenetv2\", \"log_mobilenetv2.csv\")\n\ncallbacks_mobilenetv2 = [\n    ModelCheckpoint(model_path_mobilenetv2, verbose=1, save_best_only=True),\n    ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-7, verbose=1),\n    CSVLogger(csv_path_mobilenetv2),\n    EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=False),\n]","metadata":{"execution":{"iopub.status.busy":"2023-12-31T08:18:00.221599Z","iopub.execute_input":"2023-12-31T08:18:00.222321Z","iopub.status.idle":"2023-12-31T08:18:00.229635Z","shell.execute_reply.started":"2023-12-31T08:18:00.222290Z","shell.execute_reply":"2023-12-31T08:18:00.228622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_mobilenetv2(input_shape):\n    # Encoder: load MobileNetV2 with pre-trained ImageNet weights\n    encoder = MobileNetV2(include_top=False, weights='imagenet', input_tensor=Input(shape=input_shape))\n\n    # Set the encoder layers to not be trainable\n    for layer in encoder.layers:\n        layer.trainable = False\n\n    # Skip connections from specific layers in MobileNetV2\n    skip_connections = ['block_1_expand_relu', 'block_3_expand_relu', 'block_6_expand_relu', 'block_13_expand_relu']\n    encoder_outputs = [encoder.get_layer(name).output for name in skip_connections]\n\n    # Decoder\n    x = encoder.output\n    num_filters = 512\n    for skip_output in reversed(encoder_outputs):\n        x = Conv2DTranspose(num_filters, (2, 2), strides=(2, 2), padding='same')(x)\n        skip_output = tf.image.resize(skip_output, tf.shape(x)[1:3], method='nearest')\n        x = Concatenate()([x, skip_output])\n        x = conv_block(x, num_filters)\n        num_filters //= 2\n\n    # Ensure the final layer has the same size as the input\n    x = Conv2DTranspose(input_shape[-1], (2, 2), strides=(2, 2), padding='same')(x)\n    outputs = Conv2D(1, (1, 1), activation='sigmoid', padding='same')(x)\n\n    # Create the model\n    model = Model(inputs=encoder.input, outputs=outputs)\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-12-31T08:18:04.310758Z","iopub.execute_input":"2023-12-31T08:18:04.311614Z","iopub.status.idle":"2023-12-31T08:18:04.321297Z","shell.execute_reply.started":"2023-12-31T08:18:04.311574Z","shell.execute_reply":"2023-12-31T08:18:04.320308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize the model\nmobilenetv2_model = build_mobilenetv2((H, W, 3))\n\n# Compile the model\nmobilenetv2_model.compile(loss=dice_loss, optimizer=Adam(lr), metrics=[dice_coef, 'accuracy', iou])\n\n# Print the model summary to check the final model architecture\nmobilenetv2_model.summary()\n\n# Train the model using the same datasets and callbacks you've defined\nhistory_mobilenetv2 = mobilenetv2_model.fit(\n    train_dataset,\n    epochs=num_epochs,\n    validation_data=valid_dataset,\n    callbacks=callbacks_mobilenetv2\n)\n\n# Save training history\nnp.save('history_mobilenetv2.npy', history_mobilenetv2.history)\n\n# Evaluate the model on your test dataset\nmobilenetv2_test_metrics = mobilenetv2_model.evaluate(test_dataset)\n\n# Save and display the test metrics\nwith open('mobilenetv2_test_metrics.txt', 'w') as file:\n    file.write(str(mobilenetv2_test_metrics))\n\nprint(f\"MobileNetV2 Test Loss: {mobilenetv2_test_metrics[0]}\")\nprint(f\"MobileNetV2 Test Dice Coefficient: {mobilenetv2_test_metrics[1]}\")\nprint(f\"MobileNetV2 Test Accuracy: {mobilenetv2_test_metrics[2]}\")\nprint(f\"MobileNetV2 Test IoU: {mobilenetv2_test_metrics[3]}\")","metadata":{"execution":{"iopub.status.busy":"2023-12-31T08:18:07.299294Z","iopub.execute_input":"2023-12-31T08:18:07.299639Z","iopub.status.idle":"2023-12-31T09:52:56.121394Z","shell.execute_reply.started":"2023-12-31T08:18:07.299614Z","shell.execute_reply":"2023-12-31T09:52:56.120397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"   \"\"\"Prediction and Evaluation\"\"\"\nSCORE_mobilenetv2= []\nfor x, y in tqdm(zip(test_x, test_y), total=len(test_y)):\n    \"\"\" Extracting the name \"\"\"\n    name = x.split(\"/\")[-1]\n\n\n    \"\"\" Reading the image \"\"\"\n    image = cv2.imread(x, cv2.IMREAD_COLOR) ## [H, w, 3]\n    image = cv2.resize(image, (W, H))       ## [H, w, 3]\n    x = image/255.0                         ## [H, w, 3]\n    x = np.expand_dims(x, axis=0)           ## [1, H, w, 3]\n\n    \"\"\" Reading the mask \"\"\"\n    mask = cv2.imread(y, cv2.IMREAD_GRAYSCALE)\n    mask = cv2.resize(mask, (W, H))\n\n    \"\"\" Prediction \"\"\"\n    y_pred = mobilenetv2_model.predict(x, verbose=0)[0]\n    y_pred = np.squeeze(y_pred, axis=-1)\n    y_pred = y_pred >= 0.5\n    y_pred = y_pred.astype(np.int32)\n\n    \"\"\" Saving the prediction \"\"\"\n    save_image_path = os.path.join(\"results_resnet50 \", name)\n    save_results(image, mask, y_pred, save_image_path)\n\n    \"\"\" Flatten the array \"\"\"\n    mask = mask/255.0\n    mask = (mask > 0.5).astype(np.int32).flatten()\n    y_pred = y_pred.flatten()\n\n    \"\"\" Calculating the metrics values \"\"\"\n    accuracy = accuracy_score(mask, y_pred)\n    f1_value = f1_score(mask, y_pred, labels=[0, 1], average=\"binary\")\n    jac_value = jaccard_score(mask, y_pred, labels=[0, 1], average=\"binary\")\n    recall_value = recall_score(mask, y_pred, labels=[0, 1], average=\"binary\", zero_division=0)\n    precision_value = precision_score(mask, y_pred, labels=[0, 1], average=\"binary\", zero_division=0)\n    SCORE_mobilenetv2.append([name, accuracy, f1_value, jac_value, recall_value, precision_value])\n\n\"\"\" Metrics values \"\"\"\nscore_mobilenetv2 = [s[1:]for s in SCORE_mobilenetv2]\nscore_mobilenetv2 = np.mean(score_mobilenetv2, axis=0)\nprint(f\"Accuracy: {score_mobilenetv2[0]:0.5f}\")\nprint(f\"F1: {score_mobilenetv2[1]:0.5f}\")\nprint(f\"Jaccard: {score_mobilenetv2[2]:0.5f}\")\nprint(f\"Recall: {score_mobilenetv2[3]:0.5f}\")\nprint(f\"Precision: {score_mobilenetv2[4]:0.5f}\")\n\ndf = pd.DataFrame(SCORE_resnet50, columns=[\"Image\", \"Accuracy\", \"F1\", \"Jaccard\", \"Recall\", \"Precision\"])\ndf.to_csv(\"files/score_mobilenetv2.csv\", index=None)","metadata":{"execution":{"iopub.status.busy":"2023-12-31T09:55:35.050956Z","iopub.execute_input":"2023-12-31T09:55:35.051948Z","iopub.status.idle":"2023-12-31T09:57:38.766945Z","shell.execute_reply.started":"2023-12-31T09:55:35.051896Z","shell.execute_reply":"2023-12-31T09:57:38.765994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores = pd.read_csv(\"/kaggle/working/files/score_mobilenetv2.csv\")\nscores.head(3)","metadata":{"execution":{"iopub.status.busy":"2023-12-31T09:57:57.569218Z","iopub.execute_input":"2023-12-31T09:57:57.570111Z","iopub.status.idle":"2023-12-31T09:57:57.585959Z","shell.execute_reply.started":"2023-12-31T09:57:57.570076Z","shell.execute_reply":"2023-12-31T09:57:57.584794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\n# Paths to the metrics files\nmetrics_files = {\n    'UNet': '/kaggle/working/unet_test_metrics.txt',\n    'VGG16': '/kaggle/working/vgg16_test_metrics.txt',\n    'VGG19': '/kaggle/working/vgg19_test_metrics.txt',\n    'ResNet50': '/kaggle/working/resnet50_test_metrics.txt',\n    'MobileNetV2': '/kaggle/working/mobilenetv2_test_metrics.txt'\n}\n\n# Read the metrics into a DataFrame\nmetrics_data = []\nfor model, filepath in metrics_files.items():\n    with open(filepath, 'r') as file:\n        # Assuming that each file has a single line with the metrics in order\n        metrics = file.readline().strip().strip('[]').split(',')\n        metrics_data.append([model] + [float(metric.strip()) for metric in metrics])\n\n# Assuming the order is Loss, Dice Coefficient, Accuracy, IoU\ndf_metrics = pd.DataFrame(metrics_data, columns=['Model', 'Test Loss', 'Dice Coefficient', 'Accuracy', 'IoU'])\n\nprint(df_metrics)","metadata":{"execution":{"iopub.status.busy":"2023-12-31T13:13:25.424469Z","iopub.execute_input":"2023-12-31T13:13:25.424837Z","iopub.status.idle":"2023-12-31T13:13:25.436804Z","shell.execute_reply.started":"2023-12-31T13:13:25.424804Z","shell.execute_reply":"2023-12-31T13:13:25.435855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Assuming df_metrics is your DataFrame\n# with columns 'Model', 'Test Loss', 'Dice Coefficient', 'Accuracy', 'IoU'\n\n# Set the style\nsns.set(style=\"whitegrid\")\n\n# Melt the DataFrame to make it suitable for sns.barplot\ndf_melted = df_metrics.melt(id_vars='Model', var_name='Metric', value_name='Score')\n\n# Set the size of the figure\nplt.figure(figsize=(14, 8))\n\n# Create the barplot\nax = sns.barplot(x='Metric', y='Score', hue='Model', data=df_melted)\n\n# Customize the plot to make it more appealing\nax.set_title('Comparative Performance Metrics Across Models', fontsize=18, pad=20)\nax.set_xlabel('Metric', fontsize=14, labelpad=15)\nax.set_ylabel('Score', fontsize=14, labelpad=15)\nax.tick_params(labelsize=12)\n\n# Add value labels on top of the bars\nfor container in ax.containers:\n    ax.bar_label(container, fmt='%.2f', label_type='edge', padding=3, fontsize=10)\n\n# Increase the bottom margin to accommodate model names\nplt.subplots_adjust(bottom=0.15)\n\n# Move the legend outside of the plot\nplt.legend(title='Model', title_fontsize='13', loc='upper left', bbox_to_anchor=(1, 1), fontsize=12)\n\n# Display the plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-31T14:47:11.427717Z","iopub.execute_input":"2023-12-31T14:47:11.428546Z","iopub.status.idle":"2023-12-31T14:47:11.966372Z","shell.execute_reply.started":"2023-12-31T14:47:11.428508Z","shell.execute_reply":"2023-12-31T14:47:11.965279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\n\n# Paths to the CSV files for each model\nmodel_paths = {\n    'UNet': '/kaggle/working/files/log.csv',\n    'VGG16': '/kaggle/working/files_vgg16/log_vgg16.csv',\n    'VGG19': '/kaggle/working/files_vgg19/log_vgg19.csv',\n    'ResNet50': '/kaggle/working/files_resnet50/log_resnet50.csv',\n    'MobileNetV2': '/kaggle/working/files_mobilenetv2/log_mobilenetv2.csv'\n}\n\n# Metrics to plot\nmetrics = ['accuracy', 'dice_coef', 'iou', 'loss']\n\n# Set the aesthetic style of the plots\nsns.set_style(\"whitegrid\")\n\n# Plot training metrics for each model\nfor model_name, file_path in model_paths.items():\n    # Load the CSV file into a DataFrame\n    df_metrics = pd.read_csv(file_path)\n\n    # Create a line plot for each metric\n    fig, axs = plt.subplots(1, 4, figsize=(20, 5), sharex=True)\n    fig.suptitle(f'{model_name} Training Progression', fontsize=16)\n\n    for i, metric in enumerate(metrics):\n        axs[i].plot(df_metrics['epoch'], df_metrics[metric], label=f'Train {metric}')\n        axs[i].plot(df_metrics['epoch'], df_metrics[f'val_{metric}'], label=f'Val {metric}')\n        axs[i].set_title(f'{metric.capitalize()} Over Epochs')\n        axs[i].set_xlabel('Epoch')\n        axs[i].set_ylabel(metric.capitalize())\n        axs[i].legend()\n\n    # Show the plot with a tight layout\n    plt.tight_layout()\n    plt.subplots_adjust(top=0.88)  # Adjust the top to fit the suptitle\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-31T11:54:47.435184Z","iopub.execute_input":"2023-12-31T11:54:47.435893Z","iopub.status.idle":"2023-12-31T11:54:55.174406Z","shell.execute_reply.started":"2023-12-31T11:54:47.435861Z","shell.execute_reply":"2023-12-31T11:54:55.173410Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#saving above plot\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nfrom IPython.display import FileLink\n\n# Paths to the CSV files for each model\nmodel_paths = {\n    'UNet': '/kaggle/working/files/log.csv',\n    'VGG16': '/kaggle/working/files_vgg16/log_vgg16.csv',\n    'VGG19': '/kaggle/working/files_vgg19/log_vgg19.csv',\n    'ResNet50': '/kaggle/working/files_resnet50/log_resnet50.csv',\n    'MobileNetV2': '/kaggle/working/files_mobilenetv2/log_mobilenetv2.csv'\n}\n\n# Metrics to plot\nmetrics = ['accuracy', 'dice_coef', 'iou', 'loss']\n\n# Set the aesthetic style of the plots\nsns.set_style(\"whitegrid\")\n\n# Plot training metrics for each model\nfor model_name, file_path in model_paths.items():\n    # Load the CSV file into a DataFrame\n    df_metrics = pd.read_csv(file_path)\n\n    # Create a line plot for each metric\n    fig, axs = plt.subplots(1, 4, figsize=(20, 5), sharex=True)\n    fig.suptitle(f'{model_name} Training Progression', fontsize=16)\n\n    for i, metric in enumerate(metrics):\n        axs[i].plot(df_metrics['epoch'], df_metrics[metric], label=f'Train {metric}')\n        axs[i].plot(df_metrics['epoch'], df_metrics[f'val_{metric}'], label=f'Val {metric}')\n        axs[i].set_title(f'{metric.capitalize()} Over Epochs')\n        axs[i].set_xlabel('Epoch')\n        axs[i].set_ylabel(metric.capitalize())\n        axs[i].legend()\n\n    # Save the plot to a file\n    plot_filename = f'/kaggle/working/{model_name.lower()}_training_progression.png'\n    plt.savefig(plot_filename)\n    plt.close(fig)  # Close the figure to avoid displaying it in the notebook\n\n    # Create a link to download the saved plot\n    display(FileLink(plot_filename))","metadata":{"execution":{"iopub.status.busy":"2023-12-31T11:54:55.914491Z","iopub.execute_input":"2023-12-31T11:54:55.915277Z","iopub.status.idle":"2023-12-31T11:55:00.133267Z","shell.execute_reply.started":"2023-12-31T11:54:55.915234Z","shell.execute_reply":"2023-12-31T11:55:00.132110Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# File paths\nscore_files = {\n    'U-Net': '/kaggle/working/files/score.csv',\n    'VGG16': '/kaggle/working/files/score_vgg16.csv',\n    'VGG19': '/kaggle/working/files/score_vgg19.csv',\n    'ResNet50': '/kaggle/working/files/score_resnet50.csv',\n    'MobileNetV2': '/kaggle/working/files/score_mobilenetv2.csv'\n}\n\n# Read and combine the data\nall_scores = []\nfor model, file_path in score_files.items():\n    df = pd.read_csv(file_path)\n    df['Model'] = model  # Add a column for the model name\n    all_scores.append(df)\n\ncombined_scores = pd.concat(all_scores)\n\n# Reshape the data\nmelted_scores = combined_scores.melt(id_vars='Model', \n                                     value_vars=['F1', 'Jaccard', 'Recall', 'Precision'], \n                                     var_name='Metric', \n                                     value_name='Score')\n\n# Set the style\nsns.set(style=\"whitegrid\")\n\n# Set the size of the figure\nplt.figure(figsize=(14, 8))\n\n# Create the barplot\nax = sns.barplot(x='Metric', y='Score', hue='Model', data=melted_scores, errorbar=None)\n\n# Customize the plot to make it more appealing\nax.set_title('Comparative Evaluation Metrics Across Models', fontsize=18, pad=20)\nax.set_xlabel('Metric', fontsize=14, labelpad=15)\nax.set_ylabel('Score', fontsize=14, labelpad=15)\nax.tick_params(labelsize=12)\n\n# Add value labels on top of the bars\nfor container in ax.containers:\n    ax.bar_label(container, fmt='%.2f', label_type='edge', padding=3, fontsize=10)\n\n# Increase the bottom margin to accommodate model names\nplt.subplots_adjust(bottom=0.15)\n\n# Move the legend outside of the plot\nplt.legend(title='Model', title_fontsize='13', loc='upper left', bbox_to_anchor=(1, 1), fontsize=12)\n\n# Display the plot\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-12-31T14:43:23.550433Z","iopub.execute_input":"2023-12-31T14:43:23.550855Z","iopub.status.idle":"2023-12-31T14:43:24.066255Z","shell.execute_reply.started":"2023-12-31T14:43:23.550823Z","shell.execute_reply":"2023-12-31T14:43:24.065130Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Assuming df_metrics is your DataFrame\n# with columns 'Model', 'Test Loss', 'Dice Coefficient', 'Accuracy', 'IoU'\n\n# Set the style\nsns.set(style=\"whitegrid\", palette=\"pastel\")\n\n# Melt the DataFrame to make it suitable for sns.barplot\ndf_melted = df_metrics.melt(id_vars='Model', var_name='Metric', value_name='Score')\n\n# Set the size of the figure\nplt.figure(figsize=(14, 8))\n\n# Create the barplot\nax = sns.barplot(x='Metric', y='Score', hue='Model', data=df_melted)\n\n# Customize the plot to make it more appealing\nax.set_title('Comparative Performance Metrics Across Models', fontsize=18, pad=20)\nax.set_xlabel('Metric', fontsize=14, labelpad=15)\nax.set_ylabel('Score', fontsize=14, labelpad=15)\nax.tick_params(labelsize=12)\n\n# Add value labels on top of the bars\nfor container in ax.containers:\n    ax.bar_label(container, fmt='%.2f', label_type='edge', padding=3, fontsize=10)\n\n# Increase the bottom margin to accommodate model names\nplt.subplots_adjust(bottom=0.15)\n\n# Move the legend outside of the plot\nplt.legend(title='Model', title_fontsize='13', loc='upper left', bbox_to_anchor=(1, 1), fontsize=12)\n\n# Display the plot\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# File paths\nscore_files = {\n    'U-Net': '/kaggle/working/files/score.csv',\n    'VGG16': '/kaggle/working/files/score_vgg16.csv',\n    'VGG19': '/kaggle/working/files/score_vgg19.csv',\n    'ResNet50': '/kaggle/working/files/score_resnet50.csv',\n    'MobileNetV2': '/kaggle/working/files/score_mobilenetv2.csv'\n}\n\n# Read and combine the data\nall_scores = []\nfor model, file_path in score_files.items():\n    df = pd.read_csv(file_path)\n    df['Model'] = model  # Add a column for the model name\n    all_scores.append(df)\n\ncombined_scores = pd.concat(all_scores)\n\n# Reshape the data\nmelted_scores = combined_scores.melt(id_vars=['Model', 'Image'], \n                                     value_vars=['F1', 'Jaccard', 'Recall', 'Precision'], \n                                     var_name='Metric', \n                                     value_name='Score')\n\n# Plotting\nplt.figure(figsize=(12, 6))\nbar_plot = sns.barplot(x='Model', y='Score', hue='Metric', data=melted_scores,errorbar=None)\n\n# Adding labels\nfor p in bar_plot.patches:\n    bar_plot.annotate(format(p.get_height(), '.2f'), \n                      (p.get_x() + p.get_width() / 2., p.get_height()), \n                      ha = 'center', va = 'center', \n                      xytext = (0, 9), \n                      textcoords = 'offset points')\n\nplt.title('Performance Metrics for Different Models')\nplt.xlabel('Model')\nplt.ylabel('Score')\nplt.legend(title='Metric')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-12-31T14:36:23.734564Z","iopub.execute_input":"2023-12-31T14:36:23.735422Z","iopub.status.idle":"2023-12-31T14:36:24.225874Z","shell.execute_reply.started":"2023-12-31T14:36:23.735386Z","shell.execute_reply":"2023-12-31T14:36:24.224998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12, 6))\nbar_plot = sns.barplot(x='Model', y='Score', hue='Metric', data=melted_scores, ci=None)  # Added ci=None to remove error bars\n\n# The rest of your code remains the same\n...\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the metrics\nax = metrics_df.plot(kind='bar', figsize=(10, 7), width=0.8)\nplt.title('Test Metrics Comparison Across Models')\nplt.ylabel('Value')\nplt.xticks(rotation=45)\nplt.legend(title='Metric', bbox_to_anchor=(1.05, 1), loc='upper left')  # Moves the legend outside of the plot\nplt.tight_layout(rect=[0, 0, 0.85, 1])  # Adjust the rect to prevent the legend from cutting off\n\n# Adding labels on top of each bar\nfor p in ax.patches:\n    # Calculate index for x-tick labels\n    index = int(p.get_x() + p.get_width() / 2.0) // len(numeric_cols)\n    model_name = ax.get_xticklabels()[index].get_text()\n    \n    # Set different offsets for labels, especially for the last set of bars\n    offset = (0, 10) if 'MobileNetV2' not in model_name else (0, 30)\n    ax.annotate(f\"{p.get_height():.2f}\", \n                (p.get_x() + p.get_width() / 2., p.get_height()), \n                ha='center', va='center', \n                xytext=offset, \n                textcoords='offset points')\n\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-12-31T13:05:01.512916Z","iopub.execute_input":"2023-12-31T13:05:01.513821Z","iopub.status.idle":"2023-12-31T13:05:02.175842Z","shell.execute_reply.started":"2023-12-31T13:05:01.513788Z","shell.execute_reply":"2023-12-31T13:05:02.174861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}